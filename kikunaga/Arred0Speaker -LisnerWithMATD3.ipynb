{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (23.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: pettingzoo[mpe]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: agilerl in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (0.1.19)\n",
      "Requirement already satisfied: SuperSuit<4.0.0,>=3.9.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (3.9.1)\n",
      "Requirement already satisfied: accelerate<0.19.0,>=0.18.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (0.18.0)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.7 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (0.3.7)\n",
      "Requirement already satisfied: fastrand<2.0.0,>=1.3.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (1.8.0)\n",
      "Requirement already satisfied: flatten_dict<0.5.0,>=0.4.2 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (0.4.2)\n",
      "Requirement already satisfied: gymnasium<0.29.0,>=0.28.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (0.28.1)\n",
      "Requirement already satisfied: h5py<4.0.0,>=3.8.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (3.9.0)\n",
      "Requirement already satisfied: hydra-core<2.0.0,>=1.3.2 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (1.3.2)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.4.3 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (3.8.0)\n",
      "Requirement already satisfied: minari<0.5.0,>=0.4.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (0.4.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.2 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (1.26.2)\n",
      "Requirement already satisfied: omegaconf<3.0.0,>=2.3.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (2.3.0)\n",
      "Requirement already satisfied: pettingzoo<2.0.0,>=1.23.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (1.24.2)\n",
      "Requirement already satisfied: pre-commit<4.0.0,>=3.4.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (3.6.0)\n",
      "Requirement already satisfied: redis<5.0.0,>=4.4.4 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (4.6.0)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (1.1.0)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.0.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (2.3.0.dev20231214)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (4.66.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.30.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (4.36.1)\n",
      "Requirement already satisfied: wandb<0.14.0,>=0.13.10 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from agilerl) (0.13.11)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from accelerate<0.19.0,>=0.18.0->agilerl) (23.1)\n",
      "Requirement already satisfied: psutil in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from accelerate<0.19.0,>=0.18.0->agilerl) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from accelerate<0.19.0,>=0.18.0->agilerl) (6.0.1)\n",
      "Requirement already satisfied: six<2.0,>=1.12 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from flatten_dict<0.5.0,>=0.4.2->agilerl) (1.16.0)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from gymnasium<0.29.0,>=0.28.1->agilerl) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from gymnasium<0.29.0,>=0.28.1->agilerl) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from gymnasium<0.29.0,>=0.28.1->agilerl) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from gymnasium<0.29.0,>=0.28.1->agilerl) (0.0.4)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from hydra-core<2.0.0,>=1.3.2->agilerl) (4.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.4.3->agilerl) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.4.3->agilerl) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.4.3->agilerl) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.4.3->agilerl) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.4.3->agilerl) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.4.3->agilerl) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.4.3->agilerl) (2.8.2)\n",
      "Requirement already satisfied: google-cloud-storage==2.5.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from minari<0.5.0,>=0.4.1->agilerl) (2.5.0)\n",
      "Requirement already satisfied: typer==0.9.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from typer[all]==0.9.0->minari<0.5.0,>=0.4.1->agilerl) (0.9.0)\n",
      "Requirement already satisfied: portion==2.4.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from minari<0.5.0,>=0.4.1->agilerl) (2.4.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (2.22.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (2.15.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (2.7.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (2.31.0)\n",
      "Requirement already satisfied: sortedcontainers~=2.2 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from portion==2.4.0->minari<0.5.0,>=0.4.1->agilerl) (2.4.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from typer==0.9.0->typer[all]==0.9.0->minari<0.5.0,>=0.4.1->agilerl) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from typer[all]==0.9.0->minari<0.5.0,>=0.4.1->agilerl) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from typer[all]==0.9.0->minari<0.5.0,>=0.4.1->agilerl) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from typer[all]==0.9.0->minari<0.5.0,>=0.4.1->agilerl) (13.7.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from pre-commit<4.0.0,>=3.4.0->agilerl) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from pre-commit<4.0.0,>=3.4.0->agilerl) (2.5.33)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from pre-commit<4.0.0,>=3.4.0->agilerl) (1.8.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from pre-commit<4.0.0,>=3.4.0->agilerl) (20.25.0)\n",
      "Requirement already satisfied: tinyscaler>=1.2.6 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from SuperSuit<4.0.0,>=3.9.0->agilerl) (1.2.7)\n",
      "Requirement already satisfied: filelock in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from torch<3.0.0,>=2.0.1->agilerl) (3.13.1)\n",
      "Requirement already satisfied: sympy in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from torch<3.0.0,>=2.0.1->agilerl) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from torch<3.0.0,>=2.0.1->agilerl) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from torch<3.0.0,>=2.0.1->agilerl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from torch<3.0.0,>=2.0.1->agilerl) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from transformers<5.0.0,>=4.30.0->agilerl) (0.19.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from transformers<5.0.0,>=4.30.0->agilerl) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from transformers<5.0.0,>=4.30.0->agilerl) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from transformers<5.0.0,>=4.30.0->agilerl) (0.4.1)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from wandb<0.14.0,>=0.13.10->agilerl) (3.1.40)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from wandb<0.14.0,>=0.13.10->agilerl) (1.39.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from wandb<0.14.0,>=0.13.10->agilerl) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from wandb<0.14.0,>=0.13.10->agilerl) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from wandb<0.14.0,>=0.13.10->agilerl) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from wandb<0.14.0,>=0.13.10->agilerl) (69.0.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from wandb<0.14.0,>=0.13.10->agilerl) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from wandb<0.14.0,>=0.13.10->agilerl) (3.20.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb<0.14.0,>=0.13.10->agilerl) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (2023.11.17)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from virtualenv>=20.10.0->pre-commit<4.0.0,>=3.4.0->agilerl) (0.3.8)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from virtualenv>=20.10.0->pre-commit<4.0.0,>=3.4.0->agilerl) (4.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from jinja2->torch<3.0.0,>=2.0.1->agilerl) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from sympy->torch<3.0.0,>=2.0.1->agilerl) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb<0.14.0,>=0.13.10->agilerl) (5.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (1.62.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (4.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from google-resumable-media>=2.3.2->google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (1.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from rich<14.0.0,>=10.11.0->typer[all]==0.9.0->minari<0.5.0,>=0.4.1->agilerl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from rich<14.0.0,>=10.11.0->typer[all]==0.9.0->minari<0.5.0,>=0.4.1->agilerl) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]==0.9.0->minari<0.5.0,>=0.4.1->agilerl) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage==2.5.0->minari<0.5.0,>=0.4.1->agilerl) (0.4.8)\n",
      "Requirement already satisfied: imageio in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (2.33.1)\n",
      "Requirement already satisfied: numpy in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from imageio) (1.26.2)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /Users/kikunagarikuto/anaconda3/envs/pytorch-tensorflow/lib/python3.11/site-packages (from imageio) (10.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pettingzoo[mpe]\n",
    "!pip install agilerl\n",
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pettingzoo.mpe import simple_speaker_listener_v4\n",
    "from tqdm import trange\n",
    "\n",
    "from agilerl.components.multi_agent_replay_buffer import MultiAgentReplayBuffer\n",
    "from agilerl.hpo.mutation import Mutations\n",
    "from agilerl.hpo.tournament import TournamentSelection\n",
    "from agilerl.utils.utils import initialPopulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datetime\n",
    "\n",
    "def get_current_datetime():\n",
    "    # 現在の日時を取得\n",
    "    dt_now = datetime.datetime.now()\n",
    "\n",
    "    # 日時を指定された形式の文字列に変換\n",
    "    str_dt_now = dt_now.strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "    return str_dt_now\n",
    "\n",
    "# この関数を呼び出して現在の日時を取得する例\n",
    "# current_datetime = get_current_datetime()\n",
    "# print(current_datetime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#environment_setup.py\n",
    "#from pettingzoo.mpe import simple_speaker_listener_v4\n",
    "\n",
    "def initialize_environment():\n",
    "    # シンプルなスピーカーリスナー環境を並列環境として定義\n",
    "    env = simple_speaker_listener_v4.parallel_env(continuous_actions=True)\n",
    "    env.reset()\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#environment_setup.py\n",
    "#import torch\n",
    "\n",
    "def define_network_config():\n",
    "    return {\n",
    "        \"arch\": \"mlp\",  # ネットワークアーキテクチャ\n",
    "        \"h_size\": [32, 32],  # アクターの隠れ層のサイズ\n",
    "    }\n",
    "\n",
    "def define_initial_hyperparameters():\n",
    "    return {\n",
    "        \"POPULATION_SIZE\": 4,\n",
    "        \"ALGO\": \"MATD3\",  # Algorithm\n",
    "        # Swap image channels dimension from last to first [H, W, C] -> [C, H, W]\n",
    "        \"CHANNELS_LAST\": False,\n",
    "        \"BATCH_SIZE\": 32,  # Batch size\n",
    "        \"LR\": 0.01,  # Learning rate\n",
    "        \"GAMMA\": 0.95,  # Discount factor\n",
    "        \"MEMORY_SIZE\": 100000,  # Max memory buffer size\n",
    "        \"LEARN_STEP\": 5,  # Learning frequency\n",
    "        \"TAU\": 0.01,  # For soft update of target parameters\n",
    "        \"POLICY_FREQ\": 2,  # Policy frequnecy\n",
    "        # ... (INIT_HP辞書の残り)\n",
    "    }\n",
    "\n",
    "def get_device():\n",
    "    #return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return torch.device(\"mps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agents.py\n",
    "#from agilerl.utils.utils import initialPopulation\n",
    "\n",
    "def set_action_and_state_dimensions(env, INIT_HP):\n",
    "    \"\"\"\n",
    "    環境から行動次元と状態次元を設定し、初期ハイパーパラメータを更新する。\n",
    "    env: 学習環境\n",
    "    init_hp: 初期ハイパーパラメータの辞書\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # まず、状態次元を設定する\n",
    "        # 状態空間が離散的か連続的かに基づいて状態次元を取得する\n",
    "        state_dim = [env.observation_space(agent).n for agent in env.agents]\n",
    "        one_hot = True\n",
    "    except Exception:\n",
    "        # 連続的な状態空間の場合\n",
    "        state_dim = [env.observation_space(agent).shape for agent in env.agents]\n",
    "        one_hot = False\n",
    "\n",
    "    try:\n",
    "        # 次に、行動次元を設定する\n",
    "        # 行動空間が離散的か連続的かに基づいて行動次元を取得する\n",
    "        action_dim = [env.action_space(agent).n for agent in env.agents]\n",
    "        INIT_HP[\"DISCRETE_ACTIONS\"] = True\n",
    "        INIT_HP[\"MAX_ACTION\"] = None\n",
    "        INIT_HP[\"MIN_ACTION\"] = None\n",
    "    except Exception:\n",
    "        # 連続的な行動空間の場合\n",
    "        action_dim = [env.action_space(agent).shape[0] for agent in env.agents]\n",
    "        INIT_HP[\"DISCRETE_ACTIONS\"] = False\n",
    "        INIT_HP[\"MAX_ACTION\"] = [env.action_space(agent).high for agent in env.agents]\n",
    "        INIT_HP[\"MIN_ACTION\"] = [env.action_space(agent).low for agent in env.agents]\n",
    "\n",
    "    if False: # デバッグ出力\n",
    "        print(\"state_dim\", state_dim)\n",
    "        print(\"one_hot\", one_hot)\n",
    "        print( 'INIT_HP[\"DISCRETE_ACTIONS\"]', INIT_HP[\"DISCRETE_ACTIONS\"])\n",
    "        print( 'INIT_HP[\"MAX_ACTION\"]', INIT_HP[\"MAX_ACTION\"])\n",
    "        print( 'INIT_HP[\"MIN_ACTION\"]', INIT_HP[\"MIN_ACTION\"])\n",
    "\n",
    "    # 状態次元の調整（CHANNELS_LAST オプションが True の場合）\n",
    "    if INIT_HP[\"CHANNELS_LAST\"]:\n",
    "        state_dim = [\n",
    "            (state_dim[2], state_dim[0], state_dim[1]) for state_dim in state_dim\n",
    "        ]\n",
    "\n",
    "    return state_dim, action_dim, INIT_HP, one_hot\n",
    "\n",
    "# Create a population ready for evolutionary hyper-parameter optimisation\n",
    "# 進化的なハイパーパラメータ最適化のための母集団を作成する\n",
    "def create_population(INIT_HP, state_dim, action_dim, one_hot, NET_CONFIG, device):\n",
    "    return initialPopulation(\n",
    "        INIT_HP[\"ALGO\"],\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        one_hot,\n",
    "        NET_CONFIG,\n",
    "        INIT_HP,\n",
    "        population_size=INIT_HP[\"POPULATION_SIZE\"],\n",
    "        device=device,\n",
    "        # ... (その他のパラメータ)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replay_buffer.py\n",
    "#from agilerl.components.multi_agent_replay_buffer import MultiAgentReplayBuffer\n",
    "\n",
    "def setup_replay_buffer(INIT_HP, device):\n",
    "    field_names = [\"state\", \"action\", \"reward\", \"next_state\", \"done\"]\n",
    "    return MultiAgentReplayBuffer(\n",
    "        INIT_HP[\"MEMORY_SIZE\"],\n",
    "        field_names=field_names,\n",
    "        agent_ids=INIT_HP[\"AGENT_IDS\"],\n",
    "        device=device,\n",
    "        # ... (その他のパラメータ)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hpo.py\n",
    "#from agilerl.hpo.mutation import Mutations\n",
    "#from agilerl.hpo.tournament import TournamentSelection\n",
    "\n",
    "# Instantiate a tournament selection object (used for HPO)\n",
    "def tournament_selection(INIT_HP):\n",
    "    return TournamentSelection(\n",
    "        tournament_size=2,  # Tournament selection size\n",
    "        elitism=True,  # Elitism in tournament selection\n",
    "        population_size=INIT_HP[\"POPULATION_SIZE\"],  # Population size\n",
    "        evo_step=1,\n",
    "        # ... (その他のパラメータ)\n",
    "    )# Evaluate using last N fitness scores\n",
    "\n",
    "# Instantiate a mutations object (used for HPO)\n",
    "def mutations_config(INIT_HP, NET_CONFIG, device):\n",
    "    return Mutations(\n",
    "        algo=INIT_HP[\"ALGO\"],\n",
    "        no_mutation=0.2,  # Probability of no mutation\n",
    "        architecture=0.2,  # Probability of architecture mutation\n",
    "        new_layer_prob=0.2,  # Probability of new layer mutation\n",
    "        parameters=0.2,  # Probability of parameter mutation\n",
    "        activation=0,  # Probability of activation function mutation\n",
    "        rl_hp=0.2,  # Probability of RL hyperparameter mutation\n",
    "        rl_hp_selection=[\n",
    "            \"lr\",\n",
    "            \"learn_step\",\n",
    "            \"batch_size\",\n",
    "        ],  # RL hyperparams selected for mutation\n",
    "        mutation_sd=0.1,  # Mutation strength\n",
    "        agent_ids=INIT_HP[\"AGENT_IDS\"],\n",
    "        arch=NET_CONFIG[\"arch\"],\n",
    "        rand_seed=2,#1,\n",
    "        device=device,\n",
    "        # ... (その他のパラメータ)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_train_data.py\n",
    "#import os\n",
    "\n",
    "def save_trained_model(model, path, filename):\n",
    "    #str_dt_now = get_current_datetime()\n",
    "    path = path#\"./models/MATD3\"\n",
    "    filename = filename#f\"MATD3_trained_agent_{str_dt_now}.pt\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    save_path = os.path.join(path, filename)\n",
    "    model.saveCheckpoint(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.py\n",
    "#import numpy as np\n",
    "#from tqdm import trange\n",
    "\n",
    "def training_loop(env, pop ,memory, tournament, mutations, INIT_HP, NET_CONFIG, max_episodes, max_steps):\n",
    "    \n",
    "    # Define training loop parameters\n",
    "    # 学習ループ・パラメータを定義\n",
    "    max_episodes = 10 # 6000 #500  # Total episodes (default: 6000)\n",
    "    max_steps = 100 #25  # Maximum steps to take in each episode\n",
    "    epsilon = 1.0  # Starting epsilon value\n",
    "    eps_end = 0.1  # Final epsilon value\n",
    "    eps_decay = 0.995  # Epsilon decay\n",
    "    evo_epochs = 20  # Evolution frequency\n",
    "    evo_loop = 1  # Number of evaluation episodes\n",
    "    elite = population[0]  # Assign a placeholder \"elite\" agent\n",
    "    \n",
    "    # Training loop\n",
    "    # 学習ループ\n",
    "    for idx_epi in trange(max_episodes):\n",
    "        \n",
    "        for agent in population:  # Loop through population\n",
    "            \n",
    "            state, info = env.reset()  # Reset environment at start of episode\n",
    "            agent_reward = {agent_id: 0 for agent_id in env.agents}\n",
    "            if INIT_HP[\"CHANNELS_LAST\"]:\n",
    "                state = {\n",
    "                    agent_id: np.moveaxis(np.expand_dims(s, 0), [-1], [-3])\n",
    "                    for agent_id, s in state.items()\n",
    "                }\n",
    "\n",
    "            for _ in range(max_steps):\n",
    "                agent_mask = info[\"agent_mask\"] if \"agent_mask\" in info.keys() else None\n",
    "                env_defined_actions = (\n",
    "                    info[\"env_defined_actions\"]\n",
    "                    if \"env_defined_actions\" in info.keys()\n",
    "                    else None\n",
    "                )\n",
    "\n",
    "                # Get next action from agent\n",
    "                # エージェントから次の行動を取得する\n",
    "                cont_actions, discrete_action = agent.getAction(\n",
    "                    state, epsilon, agent_mask, env_defined_actions\n",
    "                )\n",
    "                if agent.discrete_actions:\n",
    "                    action = discrete_action\n",
    "                else:\n",
    "                    action = cont_actions\n",
    "\n",
    "                next_state, reward, termination, truncation, info = env.step(\n",
    "                    action\n",
    "                )  # Act in environment\n",
    "\n",
    "                # Image processing if necessary for the environment\n",
    "                # 環境に応じた画像処理を行う\n",
    "                if INIT_HP[\"CHANNELS_LAST\"]:\n",
    "                    state = {agent_id: np.squeeze(s) for agent_id, s in state.items()}\n",
    "                    next_state = {\n",
    "                        agent_id: np.moveaxis(ns, [-1], [-3])\n",
    "                        for agent_id, ns in next_state.items()\n",
    "                    }\n",
    "\n",
    "                # Save experiences to replay buffer\n",
    "                # 経験をリプレイバッファに保存する\n",
    "                memory.save2memory(state, cont_actions, reward, next_state, termination)\n",
    "\n",
    "                # Collect the reward\n",
    "                # 報酬を受け取る\n",
    "                for agent_id, r in reward.items():\n",
    "                    agent_reward[agent_id] += r\n",
    "\n",
    "                # Learn according to learning frequency\n",
    "                # 学習周期に合わせて学習する\n",
    "                if (memory.counter % agent.learn_step == 0) and (\n",
    "                    len(memory) >= agent.batch_size\n",
    "                ):\n",
    "                    experiences = memory.sample(\n",
    "                        agent.batch_size\n",
    "                    )  # Sample replay buffer\n",
    "                    agent.learn(experiences)  # Learn according to agent's RL algorithm\n",
    "\n",
    "                # Update the state\n",
    "                # 状態を更新する\n",
    "                if INIT_HP[\"CHANNELS_LAST\"]:\n",
    "                    next_state = {\n",
    "                        agent_id: np.expand_dims(ns, 0)\n",
    "                        for agent_id, ns in next_state.items()\n",
    "                    }\n",
    "                state = next_state\n",
    "\n",
    "                # Stop episode if any agents have terminated\n",
    "                # いずれかのエージェントが終了したならば、エピソードを停止する\n",
    "                if any(truncation.values()) or any(termination.values()):\n",
    "                    break\n",
    "\n",
    "            # Save the total episode reward\n",
    "            # エピソードの合計報酬を保存する\n",
    "            score = sum(agent_reward.values())\n",
    "            agent.scores.append(score)\n",
    "\n",
    "        # Update epsilon for exploration\n",
    "        # 探索用のイプシロンを更新\n",
    "        epsilon = max(eps_end, epsilon * eps_decay)\n",
    "\n",
    "        # Now evolve population if necessary\n",
    "        # 必要であれば、母集団を進化させる\n",
    "        if (idx_epi + 1) % evo_epochs == 0:\n",
    "            # Evaluate population\n",
    "            fitnesses = [\n",
    "                agent.test(\n",
    "                    env,\n",
    "                    swap_channels=INIT_HP[\"CHANNELS_LAST\"],\n",
    "                    max_steps=max_steps,\n",
    "                    loop=evo_loop,\n",
    "                )\n",
    "                for agent in population\n",
    "            ]\n",
    "\n",
    "            print(f\"Episode {idx_epi + 1}/{max_episodes}\")\n",
    "            print(f'Fitnesses: {[\"%.2f\" % fitness for fitness in fitnesses]}')\n",
    "            print(\n",
    "                f'100 fitness avgs: {[\"%.2f\" % np.mean(agent.fitness[-100:]) for agent in population]}'\n",
    "            )\n",
    "\n",
    "            # Tournament selection and population mutation\n",
    "            # トーナメント選択と母集団の変異\n",
    "            elite, population = tournament.select(population)\n",
    "            population = mutations.mutation(population)\n",
    "    return elite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main.py\n",
    "#import datetime\n",
    "#import numpy as np\n",
    "#from tqdm import trange\n",
    "#import os\n",
    "\n",
    "#import pprint\n",
    "\n",
    "# モジュールをインポート\n",
    "#import environment_setup\n",
    "#import config\n",
    "#import agents\n",
    "#import replay_buffer\n",
    "#import hpo\n",
    "#import train\n",
    "\n",
    "def main():\n",
    "    device = get_device()\n",
    "    \n",
    "    print(\"===== AgileRL Online Multi-Agent Demo =====\")\n",
    "    \n",
    "    NET_CONFIG = define_network_config()\n",
    "    INIT_HP = define_initial_hyperparameters()\n",
    "    env = initialize_environment()\n",
    "    \n",
    "    # Append number of agents and agent IDs to the initial hyperparameter dictionary\n",
    "    # エージェントとエージェントIDの数を、ハイパーパラメータディクショナリの初期化のために加える\n",
    "    INIT_HP[\"N_AGENTS\"] = env.num_agents\n",
    "    INIT_HP[\"AGENT_IDS\"] = env.agents\n",
    "    \n",
    "    if True: # デバッグ出力\n",
    "        print('state_dim', state_dim)\n",
    "        print('action_dim', action_dim)\n",
    "        print('one_hot', one_hot)\n",
    "        print('NET_CONFIG')\n",
    "        pprint.pprint(NET_CONFIG)\n",
    "        print('INIT_HP')\n",
    "        pprint.pprint(INIT_HP)\n",
    "        print('device', device)\n",
    "    \n",
    "    state_dim, action_dim, INIT_HP, one_hot = set_action_and_state_dimensions(env, INIT_HP)\n",
    "    pop = create_population(INIT_HP[\"ALGO\"], state_dim, action_dim, one_hot, NET_CONFIG, INIT_HP, INIT_HP[\"POPULATION_SIZE\"], device)\n",
    "    memory = setup_replay_buffer(INIT_HP, env.agent, device=device)\n",
    "    tournament = tournament_selection(INIT_HP)\n",
    "    mutations = mutations_config(INIT_HP, NET_CONFIG)\n",
    "    \n",
    "    training_loop(env, pop ,memory, tournament, mutations, INIT_HP, NET_CONFIG, max_episodes=6000, max_steps=25)\n",
    "    trained_elite = training_loop(env, pop ,memory, tournament, mutations, INIT_HP, NET_CONFIG, max_episodes=6000, max_steps=25)\n",
    "    elite = print(trained_elite)\n",
    "    # Save the trained algorithm\n",
    "    # 学習アルゴリズムを保存する\n",
    "    str_dt_now = get_current_datetime()\n",
    "    save_trained_model(elite, \"./models/MATD3\",f\"MATD3_trained_agent_{str_dt_now}.pt\")\n",
    "    \n",
    "    ## ... (トレーニングループの残りのコード)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#environment.py\n",
    "from pettingzoo.mpe import simple_speaker_listener_v4\n",
    "\n",
    "def setup_environment(render_mode=\"rgb_array\"):\n",
    "    env = simple_speaker_listener_v4.parallel_env(continuous_actions=True, render_mode=render_mode)\n",
    "    env.reset()\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.py\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def label_with_episode_number(frame, episode_num):\n",
    "    im = Image.fromarray(frame)\n",
    "    drawer = ImageDraw.Draw(im)\n",
    "    text_color = (255, 255, 255) if np.mean(frame) < 128 else (0, 0, 0)\n",
    "    drawer.text((im.size[0] / 20, im.size[1] / 18), f\"Episode: {episode_num+1}\", fill=text_color)\n",
    "    return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.py\n",
    "from agilerl.algorithms.matd3 import MATD3\n",
    "\n",
    "def load_matd3_agent(path, state_dim, action_dim, one_hot, n_agents, agent_ids, max_action, min_action, discrete_actions, device):\n",
    "    matd3 = MATD3(state_dim, action_dim, one_hot, n_agents, agent_ids, max_action, min_action, discrete_actions, device=device)\n",
    "    matd3.loadCheckpoint(path)\n",
    "    return matd3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main.py\n",
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# モジュールのインポート\n",
    "#import environment\n",
    "#import utils\n",
    "#import agent\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    env = environment.setup_environment()\n",
    "    # ... (残りのメインスクリプトコード)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
